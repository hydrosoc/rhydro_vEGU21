<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>rHydro Presentation Theme</title>
    <meta charset="utf-8" />
    <link rel="stylesheet" href="static/css/rhydro.css" type="text/css" />
    <link rel="stylesheet" href="static/css/head-foot.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">






class: title-slide, left, middle

&lt;h1&gt;Hydrological data retrieval in R&lt;/h1&gt;

&lt;br&gt;

&lt;h3&gt;Louise Slater&lt;br&gt; &lt;em&gt;University of Oxford&lt;/em&gt; &lt;/h3&gt;
&lt;br&gt;
.small[&lt;svg style="height:0.8em;top:.04em;position:relative;fill:lightgrey;" viewBox="0 0 576 512"&gt;&lt;path d="M280.37 148.26L96 300.11V464a16 16 0 0 0 16 16l112.06-.29a16 16 0 0 0 15.92-16V368a16 16 0 0 1 16-16h64a16 16 0 0 1 16 16v95.64a16 16 0 0 0 16 16.05L464 480a16 16 0 0 0 16-16V300L295.67 148.26a12.19 12.19 0 0 0-15.3 0zM571.6 251.47L488 182.56V44.05a12 12 0 0 0-12-12h-56a12 12 0 0 0-12 12v72.61L318.47 43a48 48 0 0 0-61 0L4.34 251.47a12 12 0 0 0-1.6 16.9l25.5 31A12 12 0 0 0 45.15 301l235.22-193.74a12.19 12.19 0 0 1 15.3 0L530.9 301a12 12 0 0 0 16.9-1.6l25.5-31a12 12 0 0 0-1.7-16.93z"/&gt;&lt;/svg&gt; [louisejslater.com](https://louisejslater.com)  
&lt;svg style="height:0.8em;top:.04em;position:relative;fill:lightgrey;" viewBox="0 0 512 512"&gt;&lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/&gt;&lt;/svg&gt; [DrLouiseSlater](https://twitter.com/DrLouiseSlater)]

.title-logo-box[![](./static/img/rhydro_logo_alt.png)]


---
## Overview of hydrometric data sources

Streamflow data can be download for several countries using R packages:
* UK -&gt; [rnrfa package](https://cran.r-project.org/web/packages/rnrfa/rnrfa.pdf) by Vitolo et al. (2021)
* USA -&gt; [dataRetrieval package](https://cran.r-project.org/web/packages/dataRetrieval/dataRetrieval.pdf) by DeCicco et al. (2021)
* Canada -&gt; [tidyhydat package](https://cran.r-project.org/web/packages/tidyhydat/tidyhydat.pdf) by Albers et al. (2020)
* Greece -&gt; [hydroscoper package](https://cran.r-project.org/web/packages/hydroscoper/hydroscoper.pdf) by Vantas et al. (2021)

&lt;img src="static/img/final.PNG" width="60%" style="display: block; margin: auto;" /&gt;

Other data sources we will discuss include the CAMELS datasets (for [USA](https://hess.copernicus.org/articles/21/5293/2017/), [GB](https://doi.org/10.5194/essd-12-2459-2020),  [Australia](https://doi.org/10.5194/essd-2020-228),  [Brazil](https://doi.org/10.5194/essd-12-2075-2020),  [Chile](https://doi.org/10.5194/hess-22-5817-2018)); the African Database of Hydrometric Indices ([ADHI](https://doi.org/10.23708/LXGXQ9)); the Global Runoff Data Centre ([GRDC](https://www.bafg.de/GRDC/EN/Home/homepage_node.html)); the Global Streamflow Indices and Metadata Archive ([GSIM](https://essd.copernicus.org/articles/10/765/2018/)); and the European floods database ([Hall et al. 2015](https://piahs.copernicus.org/articles/370/89/2015/)).  



---
class: inverse, center, middle

# Before starting

---
## Install and load R packages 

Install packages:

```r
install.packages(tidyverse) # for data science functions
install.packages(ggplot2) # for nice plotting
install.packages(dataRetrieval) # USA 
install.packages(rnrfa) # UK 
install.packages(tidyhydat) # Canada
install.packages(hydroscoper) # Greece
```

Load them:

```r
library(tidyverse) 
library(ggplot2) 
library(dataRetrieval) 
library(rnrfa)
library(tidyhydat) 
library(hydroscoper) 
```


---
## Global borders 

To plot the sites, we will need a shapefile of global borders:

```r
world &lt;- map_data("world") %&gt;% 
  filter(region != "Antarctica") 

ggplot()+  
  geom_polygon(data = world, aes(long, lat, group = group), size=0.5,
               fill = "grey90", color = "gray20")+
  theme_bw()
```

![](DataRetrieval_files/figure-html/world-1.png)&lt;!-- --&gt;


---
class: inverse, center, middle

# United States

---
## United States: dataRetrieval package

We will use the dataRetrieval package by [DeCicco et al. (2021)](https://cran.r-project.org/web/packages/dataRetrieval/dataRetrieval.pdf). Useful tutorials include Laura DeCicco's [slides](https://owi.usgs.gov/R/dataRetrieval.html#1) and  [blogpost](https://waterdata.usgs.gov/blog/dataretrieval/).


What data are available?

&lt;img src="static/img/dataret.PNG" width="100%" style="display: block; margin: auto;" /&gt;


---
## United States

Let's assume we want to download streamflow data for the **entire USA**: we first need to identify the **sites** (stream gauges).

Every multiple site query requires a major **filter** (a list of sites, stateCd, huc, bBox, or countyCd). We choose **hydrologic units**:
&lt;img src="static/img/hucs.png" width="70%" style="display: block; margin: auto;" /&gt;


---
## United States

We download data for each HUC (01-21), and repeat this for all HUCs to retrieve the whole USA, e.g.:

```r
library(dataRetrieval)
USsites01 &lt;- whatNWISdata(huc="01",parameterCd="00060")
USsites02 &lt;- whatNWISdata(huc="02",parameterCd="00060")
USsites03 &lt;- whatNWISdata(huc="03",parameterCd="00060")
USsites04 &lt;- whatNWISdata(huc="04",parameterCd="00060")
USsites05 &lt;- whatNWISdata(huc="05",parameterCd="00060")
USsites06 &lt;- whatNWISdata(huc="06",parameterCd="00060")
USsites07 &lt;- whatNWISdata(huc="07",parameterCd="00060")
USsites08 &lt;- whatNWISdata(huc="08",parameterCd="00060")
... etc.
```




---
## United States

Let's make a large database for all the HUCs with all the site-information:

```r
# A long but easy way of binding all HUCs 
# (because you need to type out 21 objects):
# USsites &lt;- rbind(USsites01, USsites02....)

# Quicker approach:
hucs &lt;- paste0("USsites",sprintf('%0.2d', 1:21))
USsites &lt;-  `row.names&lt;-`(do.call(rbind,mget(hucs)), NULL)
```

---
## United States

Check the dataset -- it has 56,991 sites!

```r
head(USsites)[1:3]
```

```
##   agency_cd  site_no                                      station_nm
## 1      USGS 01010000        St. John River at Ninemile Bridge, Maine
## 2      USGS 01010000        St. John River at Ninemile Bridge, Maine
## 3      USGS 01010000        St. John River at Ninemile Bridge, Maine
## 4      USGS 01010070           Big Black River near Depot Mtn, Maine
## 5      USGS 01010070           Big Black River near Depot Mtn, Maine
## 6      USGS 01010100 Shields Br Big Black River nr Seven Islands, ME
```

Let's reduce the dataset to 9,057 sites:

```r
USsites &lt;- USsites[USsites$begin_date &lt; as.Date("1950-01-01"),]
```

---
## United States: site location


```r
ggplot()+  
  geom_polygon(data = world, aes(long, lat, group = group), size=0.5,
               fill = "gray90", color = "gray98") +
  coord_cartesian(xlim=c(-170,-60), ylim=c(18,65))+
  geom_point(data = USsites, aes(x=dec_long_va,y=dec_lat_va), 
             fill="pink", col="grey30", size=2, pch=21)+ 
  theme_bw()
```

![](DataRetrieval_files/figure-html/USmap-1.png)&lt;!-- --&gt;

---
## United States: time series

How do we retrieve the actual time series?
Let's select just one record from our database: USGS site **05420500**: 


```r
dfUS &lt;- dataRetrieval::readNWISdv("05420500","00060","","")
#Rename the streamflow variable:
names(dfUS)[names(dfUS) == 'X_00060_00003'] &lt;- 'Q'
head(dfUS)
```

```
##   agency_cd  site_no       Date      Q X_00060_00003_cd
## 1      USGS 05420500 1873-06-02  88800                A
## 2      USGS 05420500 1873-06-03  88800                A
## 3      USGS 05420500 1873-06-04  92000                A
## 4      USGS 05420500 1873-06-05  96800                A
## 5      USGS 05420500 1873-06-06 102000                A
## 6      USGS 05420500 1873-06-07 109000                A
```

---
## United States: time series

It's always worth plotting data to check for errors

```r
ggplot(dfUS)+
  geom_line(aes(x=Date, y=Q), col="blue")+
  theme_bw()
```

![](DataRetrieval_files/figure-html/USQplot-1.png)&lt;!-- --&gt;


---
class: inverse, center, middle

# United Kingdom

---
## United Kingdom: rnrfa package

We will use the **rnrfa** package by [Vitolo et al. (2021)](https://cran.r-project.org/web/packages/rnrfa/rnrfa.pdf). Check out Claudia Vitolo's [vignette](https://cran.r-project.org/web/packages/rnrfa/vignettes/rnrfa-vignette.html).

Obtain list of sites:

```r
library(rnrfa)
UKsites &lt;- rnrfa::catalogue()
UKsites &lt;- data.frame(UKsites)
# unique(UKsites$id) # list of sites
head(UKsites)[1:3] 
```

```
##     id                    name catchment.area
## 1 1001         Wick at Tarroul          161.9
## 2 2001  Helmsdale at Kilphedir          551.4
## 3 2002    Brora at Bruachrobie          434.4
## 4 3001           Shin at Lairg          494.6
## 5 3002    Carron at Sgodachail          241.1
## 6 3003 Oykel at Easter Turnaig          330.7
```

---
## United Kingdom: site location


```r
ggplot()+ theme_bw()+ 
  geom_polygon(data = world, aes(long, lat, group = group),  
               size=0.5, fill = "grey90", color = "gray98") + 
  coord_cartesian(xlim=c(-10,3), ylim=c(50,60))+
  geom_point(data = UKsites, aes(x=longitude,y=latitude), 
             pch=21, color="blue2", fill="lightblue")
```

![](DataRetrieval_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

---
## United Kingdom: time series

Download just one site: e.g. the [River Thames at Kingston](https://nrfa.ceh.ac.uk/data/station/info/39001), site 39001


```r
df &lt;- as.data.frame(gdf(id=39001, metadata = TRUE))
df$Date &lt;- as.Date(row.names(df))
names(df)[names(df) == 'gdf'] &lt;- 'Q'
```

Time series:

```r
ggplot(df)+
  geom_line(aes(x=Date, y=Q), col="blue")+
  theme_bw()
```

![](DataRetrieval_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

---
class: inverse, center, middle

# Canada

---
## Canada: hydat package


Below we use the tidyhydat package by [Albers et al. (2020)](https://cran.r-project.org/web/packages/tidyhydat/tidyhydat.pdf). Check out Sam Albers's vignettes: [intro](https://cran.r-project.org/web/packages/tidyhydat/vignettes/tidyhydat_an_introduction.html) and [examples](https://cran.r-project.org/web/packages/tidyhydat/vignettes/tidyhydat_example_analysis.html).

First, as before, retrieve list of sites:

```r
library(tidyhydat)

# download_hydat() # this takes about 10 minutes
CAsites &lt;- hy_stations()

# retrieve list of sites
sites &lt;- unique(CAsites$STATION_NUMBER)
sites[1:3] # first three
```

```
## [1] "01AA002" "01AD001" "01AD002"
```


---
## Canada: site location


```r
ggplot()+  
  geom_polygon(data = world, aes(long, lat, group = group),  size=0.5,
               fill = "grey90", color = "gray98") + 
  coord_cartesian(xlim=c(-150,-50), ylim=c(40,83))+
  geom_point(data = CAsites, aes(x=LONGITUDE,y=LATITUDE))+
  theme_bw()
```

![](DataRetrieval_files/figure-html/plothydat-1.png)&lt;!-- --&gt;

---
## Canada: time series

To download one site:

```r
dfC &lt;- hy_daily_flows(station_number = "08LA001")
names(dfC)[names(dfC) == "Value"] &lt;- "Q"
```

Time series:

```r
ggplot(dfC)+
  geom_line(aes(x=Date, y=Q), col="blue")+
  theme_bw()
```

![](DataRetrieval_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

---
class: inverse, center, middle

# Greece

---
## Greece: hydroscoper package

We will use the hydroscoper package by [Vantas et al. (2021)](https://cran.r-project.org/web/packages/hydroscoper/hydroscoper.pdf). See Konstantinos Vantas's [blogpost](https://ropensci.org/blog/2018/04/03/hydroscoper/) and [vignette: an introduction to hydroscoper](https://cran.r-project.org/web/packages/hydroscoper/vignettes/intro_hydroscoper.html).


Retrieve list of sites:


```r
library(hydroscoper)

# load full data catalogue
data("stations")
GRcatalogue &lt;- subset(stations, 
                  subdomain =  c("kyy", "ypaat", "emy", "deh"),)
```

---
## Greece: variables
  
Multiple variables are available:

```r
data("timeseries")
unique(timeseries$variable)[1:10]
```

```
##  [1] "temperature_max"        "wind_direction"        
##  [3] "temperature_min"        "flow"                  
##  [5] "snow"                   "wind_speed"            
##  [7] "wind_speed_average"     "precipitation"         
##  [9] "evaporation_estimation" "evaporation_present"
```

We only want streamflow:

```r
timeseries &lt;- subset(timeseries, variable=="flow")
# Merge in the lat/lon
GRsites &lt;- merge(timeseries, GRcatalogue, all.x=TRUE)
```

---
## Greece: site location


```r
ggplot()+  
  geom_polygon(data = world, aes(long, lat, group = group),  
               size=0.5, fill = "grey90", color = "gray98") + 
  coord_cartesian(xlim=c(20,30), ylim=c(30,40))+
  geom_point(data = GRsites, aes(x=longitude,y=latitude))+
  theme_bw()
```

![](DataRetrieval_files/figure-html/plotgr-1.png)&lt;!-- --&gt;

---
## Greece: time series

Select one site using the time_id from the dataset (GRsites)

```r
dfG &lt;- get_data(subdomain = "kyy", time_id = 753)
names(dfG)[names(dfG) == "value"] &lt;- "Q"
```

Time series:

```r
ggplot(dfG)+
  geom_line(aes(x=date, y=Q), col="blue")+
  theme_bw()
```

![](DataRetrieval_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;


---
class: inverse, center, middle

# All 4 countries

---
## All countries

Let's add together the different datasets we obtained


```r
ggplot()+  
  geom_polygon(data = world, aes(long, lat, group = group),  size=0.5,
               fill = "grey90", color = "gray98") + 
  geom_point(data = GRsites, aes(x=longitude, y=latitude),
             pch=21, size=1,col="grey50",fill="red")+
  geom_point(data = CAsites, aes(x=LONGITUDE, y=LATITUDE),
             pch=21, size=1,col="grey50",fill="orange")+
  geom_point(data = UKsites, aes(x=longitude, y=latitude),
             pch=21, size=1,col="grey50",fill="green")+
  geom_point(data = USsites, aes(x=dec_long_va, y=dec_lat_va),
             pch=21, size=1,col="grey50",fill="cyan")+
  coord_cartesian(xlim=c(-170,60), ylim=c(7,82))+
  theme_bw()
```

---
## All countries

Let's add together the different datasets we obtained

![](DataRetrieval_files/figure-html/worldmapx-1.png)&lt;!-- --&gt;

---
class: inverse, center, middle

# Additional datasets worth exploring!

---
## Global Runoff Data Centre (GRDC)

Global data can be obtained from the Global Runoff Data Centre ([GRDC](https://www.bafg.de/GRDC/EN/Home/homepage_node.html)) -- see the portal [here](https://portal.grdc.bafg.de/applications/public.html?publicuser=PublicUser#dataDownload/Home). 

&lt;img src="static/img/grdc.PNG" width="60%" style="display: block; margin: auto;" /&gt;

For instance, in this paper we combined multiple real-time datasets with the GRDC dataset: Slater et al (2021). [Global Changes in 20‐year, 50‐year and 100‐year River Floods](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091824). _Geophysical Research Letters_, e2020GL091824


---
## CAMELS datasets

The CAMELS (catchment attributes and meteorology for large-sample studies) datasets provide large integrated hydrologic datasets for regions of the world. CAMELS datasets already exist for:
* USA ([Addor et al. 2017](https://hess.copernicus.org/articles/21/5293/2017/))
* GB ([Coxon et al. 2020](https://doi.org/10.5194/essd-12-2459-2020))
* Australia ([Fowler et al. 2021](https://doi.org/10.5194/essd-2020-228))
* Brazil ([Chagas et al. 2020](https://doi.org/10.5194/essd-12-2075-2020))
* Chile ([Alvarez et al. 2018](https://doi.org/10.5194/hess-22-5817-2018)). 

They usually include both the daily **time series** and catchment **attributes** (including topography, climate, hydrology, land cover, soils, and hydrogeology), and so are an extremely valuable resource. 

---
## Africa: the ADHI

The African Database of Hydrometric Indices (ADHI) by [Tramblay &amp; Rouché 2020](https://doi.org/10.23708/LXGXQ9) contains catchment boundaries + time series for multiple stations of:
* annual minimum of 7-day discharge
* annual maximum runoff
* mean annual runoff
* streamflow percentiles (...&amp; more)

&lt;img src="static/img/ADHI_LogoAdhi.PNG" width="40%" style="display: block; margin: auto;" /&gt;


---
## GSIM

The Global Streamflow Indices and Metadata Archive ([GSIM](https://essd.copernicus.org/articles/10/765/2018/)) contains **indices and metadata**. It includes:
* A metadata catalogue; 
* Catchment boundaries;
* Catchment metadata, from 12 gridded global data products (e.g. land cover type, soil type, and climate and topographic characteristics). 

&lt;img src="static/img/GSIM.PNG" width="75%" style="display: block; margin: auto;" /&gt;


---
## European Floods Database

The European Flood Database was described in [Hall et al. 2015](https://piahs.copernicus.org/articles/370/89/2015/). Annual time series for multiple sites (1960-2010) were shared as follows:

* The **dates** of annual maximum streamflows or water levels (daily or instantaneous values) for each calendar year, for 4,062 catchments (used in [Blöschl et al. 2017](https://science.sciencemag.org/content/357/6351/588)), available [here](www.hydro.tuwien.ac.at/fileadmin/mediapool-hydro/Downloads/Data.zip). 

* The **annual maximum specific discharge** (m^3/s)/km^2 for each year (used in [Blöschl et al. 2019](https://www.nature.com/articles/s41586-019-1495-6)), available [here](https://github.com/tuwhydro/europe_floods).

---
## Conclusions

I hope you have found this useful. It is straightforward to parallelise the download for many sites at once (see the presentation from the [2019 short course](https://github.com/hydrosoc/rhydro_EGU19))!

Keep an eye on [CRAN](https://cran.r-project.org/web/packages/available_packages_by_name.html) and  the [Hydrology task force](https://cran.r-project.org/web/views/Hydrology.html) for any new packages.

And please email me if you discover any other datasets or packages, so we can update this community resource in future years! (`louise.slater@ouce.ox.ac.uk`)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
